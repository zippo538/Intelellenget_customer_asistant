{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8c4a389d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from PyPDF2 import PdfReader\n",
    "from langchain_text_splitters  import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.documents import Document\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from langchain_community.embeddings import SentenceTransformerEmbeddings\n",
    "from qdrant_client import QdrantClient\n",
    "from langchain_community.vectorstores import Qdrant\n",
    "from typing import List\n",
    "import os\n",
    "import getpass\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aab9186f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'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'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "api_key = os.getenv(\"GROQ_API_KEY\")\n",
    "api_key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad4398af",
   "metadata": {},
   "source": [
    "## Load LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "977d87a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_llm(id_model, temperature):\n",
    "    llm = ChatGroq(\n",
    "        model=id_model,\n",
    "        temperature=temperature,\n",
    "        api_key=api_key,\n",
    "        max_tokens=1024,\n",
    "        timeout=None,\n",
    "        max_retries=3\n",
    "    )\n",
    "    return llm\n",
    "\n",
    "llm = load_llm('meta-llama/llama-4-maverick-17b-128e-instruct', 0.3)\n",
    "#openai/gpt-oss-safeguard-20b\n",
    "#meta-llama/llama-4-maverick-17b-128e-instruct"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0fb0516",
   "metadata": {},
   "source": [
    "menggunakan model ini karena terbaru dan sangat mendukung integrasi Agent AI sehingga menghasilkan output yang akurat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fea395eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# document laoder\n",
    "def extract_text_from_pdf(file_path :str) -> List[Document]:\n",
    "    try : \n",
    "        \n",
    "        reader= PyMuPDFLoader(file_path)\n",
    "        docs = reader.load()\n",
    "        print(f\"✅ Berhasil memproses Dokumen\")\n",
    "        return docs\n",
    "    except Exception as e:\n",
    "        print(f\"Error saat memproses PDF : {str(e)}\")\n",
    "        return []\n",
    "#chunking text\n",
    "def chunk_text(documents : List[Document],chunk_size=1000,overlap=200) -> List[Document]:\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size= chunk_size,\n",
    "        chunk_overlap=overlap,\n",
    "        length_function=len,\n",
    "        separators=[\"\\n\\n\", \"\\n\", '\\n●','\\n1','\\n2','\\n3','\\n4','\\n5','\\n6','\\n7','\\n8','\\n9','\\n10',\" \"]\n",
    "    )\n",
    "    chunks = text_splitter.split_documents(documents)\n",
    "    print(f\"Chunking selesai. Total halaman asli : {len(documents)}\")\n",
    "    return chunks\n",
    "\n",
    "#index to qdrant\n",
    "def index_to_qdrant(chunks : List[Document], url : str , collection_name : str)-> None:\n",
    "    if not chunks:\n",
    "        print(\"❌ Tidak ada chunks yang valid untuk di-index.\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        # Inisialisasi model embedding yang akan digunakan\n",
    "        model = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "\n",
    "        print(f\"⏳ Memulai indexing ke Qdrant Collection: {collection_name}...\")\n",
    "        \n",
    "        # 2. Indexing Otomatis\n",
    "        # Qdrant.from_documents secara otomatis menangani:\n",
    "        # a) Mengubah chunks menjadi embeddings.\n",
    "        # b) Menyimpan embeddings, teks, dan metadata ke Qdrant.\n",
    "        Qdrant.from_documents(\n",
    "            documents=chunks,\n",
    "            embedding=model,\n",
    "            url = url,\n",
    "            collection_name=collection_name,\n",
    "        )\n",
    "        \n",
    "        print(\"✅ Indexing ke Qdrant Selesai!\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Gagal Indexing ke Qdrant. Cek koneksi atau API Key Anda. Error: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "d4b6a6d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Berhasil memproses Dokumen\n",
      "Chunking selesai. Total halaman asli : 31\n",
      "⏳ Memulai indexing ke Qdrant Collection: user_manual_BNI_Mbank...\n",
      "✅ Indexing ke Qdrant Selesai!\n"
     ]
    }
   ],
   "source": [
    "pdf_path = 'Handbook_BNI_Mbank.pdf'\n",
    "qdrant_url = \"http://localhost:6333\"\n",
    "collection_name = 'user_manual_BNI_Mbank'\n",
    "\n",
    "#load pdf\n",
    "text_book = extract_text_from_pdf(pdf_path)\n",
    "chunk = chunk_text(text_book)\n",
    "\n",
    "#save qdrant\n",
    "index_to_qdrant(chunk,qdrant_url,collection_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "52813d13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mencoba koneksi ke: localhost:6333\n",
      "❌ KONEKSI GAGAL: Terjadi kesalahan lain: [WinError 10061] No connection could be made because the target machine actively refused it\n"
     ]
    }
   ],
   "source": [
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http.exceptions import UnexpectedResponse\n",
    "\n",
    "# Ganti 'localhost' dan 6333 dengan alamat server Qdrant Anda\n",
    "QDRANT_HOST = \"localhost\"\n",
    "QDRANT_PORT = 6333 # Port REST API\n",
    "\n",
    "try:\n",
    "    # Buat instance klien\n",
    "    client = QdrantClient(host=QDRANT_HOST, port=QDRANT_PORT)\n",
    "    print(f\"Mencoba koneksi ke: {QDRANT_HOST}:{QDRANT_PORT}\")\n",
    "    \n",
    "    # Tambahkan timeout untuk mencegah pemblokiran yang terlalu lama (opsional, default 5 detik)\n",
    "    # client = QdrantClient(host=QDRANT_HOST, port=QDRANT_PORT, timeout=5)\n",
    "\n",
    "    # Lakukan operasi ringan yang memerlukan koneksi\n",
    "    info = client.get_collections() \n",
    "    \n",
    "    ## Alternatif: Cek informasi server (lebih mendalam)\n",
    "    # info = client.get_locks() \n",
    "    # info = client.info()\n",
    "    \n",
    "    # Jika berhasil, cetak hasilnya\n",
    "    print(\"✅ KONEKSI BERHASIL!\")\n",
    "    print(f\"Informasi Koleksi Qdrant: {info.collections}\")\n",
    "\n",
    "except ConnectionRefusedError:\n",
    "    print(f\"❌ KONEKSI GAGAL: Server Qdrant tidak berjalan atau menolak koneksi pada {QDRANT_HOST}:{QDRANT_PORT}\")\n",
    "except UnexpectedResponse as e:\n",
    "    # Terjadi jika server berjalan tetapi merespons dengan kode status error\n",
    "    print(f\"❌ KONEKSI GAGAL: Server merespons dengan Error: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ KONEKSI GAGAL: Terjadi kesalahan lain: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "20c61fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retriever\n",
    "def get_qdrant_retriever(url: str = \"http://localhost:6333\", collection_name: str = None, model_name : str = \"all-MiniLM-L6-v2\", k : int = 4):\n",
    "       \n",
    "    embedding = SentenceTransformerEmbeddings(model_name=model_name)\n",
    "    client = QdrantClient(url=url)\n",
    "    \n",
    "    qdrant = Qdrant(\n",
    "        client=client,\n",
    "        collection_name=collection_name, # <== Penentuan COLLECTION\n",
    "        embeddings=embedding,\n",
    "    )\n",
    "    retriever = qdrant.as_retriever(search_kwargs={\"k\" : k})\n",
    "    return retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7512cc78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_120\\433847635.py:7: LangChainDeprecationWarning: The class `Qdrant` was deprecated in LangChain 0.0.37 and will be removed in 1.0. An updated version of the class exists in the `langchain-qdrant package and should be used instead. To use it run `pip install -U `langchain-qdrant` and import as `from `langchain_qdrant import Qdrant``.\n",
      "  qdrant = Qdrant(\n"
     ]
    }
   ],
   "source": [
    "retriever = get_qdrant_retriever(collection_name=collection_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6af998c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template='Question: {question}\\n            Context: {context}\\n            Please provide a concise and accurate answer based on the context provided. \\n            If the context does not contain sufficient information to answer the question, respond with \"I don\\'t know.\"\\n            ')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"context\",\"question\"],\n",
    "    template=\"\"\"Question: {question}\n",
    "            Context: {context}\n",
    "            Please provide a concise and accurate answer based on the context provided. \n",
    "            If the context does not contain sufficient information to answer the question, respond with \"I don't know.\"\n",
    "            \"\"\"\n",
    ")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a01e0ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = (\n",
    "    {\"context\" :retriever, \"question\": RunnablePassthrough()}|\n",
    "    prompt |\n",
    "    llm | \n",
    "    StrOutputParser()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2846b38a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Berdasarkan konteks yang diberikan, fitur baru Whoosh yang disebutkan adalah pemesanan tiket Whoosh melalui BNI Mobile Banking di fitur Lifestyle. Berikut adalah langkah-langkah dan fitur yang terkait:\n",
      "\n",
      "1. Pilih Fitur Tiket Whoosh di BNI Mobile Banking.\n",
      "2. Lakukan pemesanan tiket Whoosh hingga pembayaran.\n",
      "3. Dapatkan tiket keberangkatanmu dalam bentuk QR Code di BNI Mobile Banking.\n",
      "\n",
      "Jadi, jawaban atas pertanyaan \"Apa aja Fitur baru Whoosh\" adalah: Pemesanan tiket Whoosh melalui BNI Mobile Banking dengan fitur mendapatkan QR Code tiket keberangkatan.\n"
     ]
    }
   ],
   "source": [
    "print(chain.invoke(\"Apa aja Fitur baru Whoosh\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca26078",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import MessagesPlaceholder\n",
    "from langchain_core.prompts.chat import ChatPromptTemplate\n",
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "from langchain.chains import create_history_aware_retriever, create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1701d264",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_q_system_prompt = \"Given the following chat history and the follow-up question which might reference \\\n",
    "    context in the chat history, rephrase the follow-up question to be a standalone question which can be unserstood without the chat history. \\\n",
    "    Do NOT answer the question, just reformulate it if needed and otherwise return it as is.\"\n",
    "\n",
    "context_q_user_prompt = \"Question : {input}\"\n",
    "\n",
    "context_q_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\",context_q_system_prompt),\n",
    "    MessagesPlaceholder(\"chat_history\"),\n",
    "    (\"human\",context_q_user_prompt)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ef5dc180",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_aware_retriever = create_history_aware_retriever(\n",
    "    llm=llm,\n",
    "    retriever=retriever,\n",
    "    prompt=context_q_prompt\n",
    ")\n",
    "\n",
    "qa_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\",context_q_system_prompt),\n",
    "    MessagesPlaceholder(\"chat_history\"),\n",
    "    (\"human\", \"Question: {input}\\nContext: {context}\\nPlease provide a concise and accurate answer based on the context provided. \\\n",
    "        If the context does not contain sufficient information to answer the question, respond with \\\"I don't know.\\\"\"), \n",
    "])\n",
    "\n",
    "qa_chain = create_stuff_documents_chain(\n",
    "    llm,\n",
    "    qa_prompt,\n",
    ")\n",
    "\n",
    "rag_chain = create_retrieval_chain(\n",
    "    history_aware_retriever,\n",
    "    qa_chain\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d345eb8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "\n",
    "\n",
    "store = {}\n",
    "\n",
    "def get_sessionhistory(session_id: str) -> BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "\n",
    "qa_chain_with_history = RunnableWithMessageHistory(\n",
    "    qa_chain,\n",
    "    get_sessionhistory,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"chat_history\"\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "bc297b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "session_id = \"user_42\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f8cc0cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = qa_chain_with_history.invoke({\n",
    "    \"input\": \"Bagaimana cara menggunakan Mbanking BNI?\",\n",
    "    \"context\":\"\"\n",
    "},config={\"configurable\": {\"session_id\": session_id}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "df9b3202",
   "metadata": {},
   "outputs": [],
   "source": [
    "response2 = qa_chain_with_history.invoke({\n",
    "    \"input\": \"Apa pertanyaan terakhir saya?\",\n",
    "    \"context\":\"\"\n",
    "},config={\"configurable\": {\"session_id\": session_id}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "228d701e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pertanyaan terakhir Anda adalah \"Bagaimana cara menggunakan Mbanking BNI?\"\n"
     ]
    }
   ],
   "source": [
    "print(response2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "748d12ee",
   "metadata": {},
   "source": [
    "## Diterapkan pada RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df6deb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history = []\n",
    "input = \"What are the latest features available in BNI Mobile Banking?\"\n",
    "\n",
    "chat_history.append(HumanMessage(content=input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e758946c",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = rag_chain.invoke({\"input\":input, \"chat_history\":chat_history})\n",
    "chat_history.append(AIMessage(content=result[\"answer\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "5a24f7a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The question \"Apa saja fitur terbaru yang tersedia di BNI Mobile Banking?\" can be rephrased as \"What are the latest features available in BNI Mobile Banking?\" without referencing the chat history. \n",
      "\n",
      "Since the provided context does not explicitly mention \"latest features\", a more accurate rephrased question would be \"What features are available in BNI Mobile Banking?\" \n",
      "\n",
      "The context does provide some information about the features available in BNI Mobile Banking, such as payment and purchase of telecommunication providers, buying voucher pulsa prabayar, and paket data. However, it does not explicitly state that these are the \"latest\" features.\n",
      "\n",
      "Therefore, the rephrased question is: \"What features are available in BNI Mobile Banking?\"\n"
     ]
    }
   ],
   "source": [
    "print(result[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "afe66efe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your last question was \"Apa saja fitur terbaru yang tersedia di BNI Mobile Banking?\".\n",
      "\n",
      "The rephrased standalone question is: \"What was my last question?\" \n",
      "\n",
      "This can be rephrased to: \"What was the previous question asked?\"\n"
     ]
    }
   ],
   "source": [
    "check_my_last_question = rag_chain.invoke({\"input\":\"what my last question\", \"chat_history\":chat_history})\n",
    "print(check_my_last_question[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "5bde4694",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To perform a transfer payment using BNI Mobile Banking via BI-Fast, follow these steps:\n",
      "\n",
      "1. Click on the \"Transfer Antar Bank\" feature in the Transfer menu.\n",
      "2. Input the data and select the transfer service type to BI-Fast.\n",
      "3. Enter your transaction password to complete the transaction.\n",
      "\n",
      "The transfer can be done 24/7, and the admin fee is Rp2,500.\n"
     ]
    }
   ],
   "source": [
    "input = \"How to perform a transfer payment using BNI Mobile Banking\"\n",
    "chat_history.append(HumanMessage(content=input))\n",
    "\n",
    "result2 = rag_chain.invoke({\"input\":input, \"chat_history\":chat_history})\n",
    "chat_history.append(AIMessage(content=result2[\"answer\"]))\n",
    "\n",
    "print(result2[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "ad804646",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pertanyaan terakhir Anda adalah \"How to perform a transfer payment using BNI Mobile Banking\".\n"
     ]
    }
   ],
   "source": [
    "check_my_last_question = rag_chain.invoke({\"input\":\"Apa pertanyaan terakhir saya\", \"chat_history\":chat_history})\n",
    "print(check_my_last_question[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "4d9d1a5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='Apa saja fitur terbaru yang tersedia di BNI Mobile Banking?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='The question \"Apa saja fitur terbaru yang tersedia di BNI Mobile Banking?\" can be rephrased as \"What are the latest features available in BNI Mobile Banking?\" without referencing the chat history. \\n\\nSince the provided context does not explicitly mention \"latest features\", a more accurate rephrased question would be \"What features are available in BNI Mobile Banking?\" \\n\\nThe context does provide some information about the features available in BNI Mobile Banking, such as payment and purchase of telecommunication providers, buying voucher pulsa prabayar, and paket data. However, it does not explicitly state that these are the \"latest\" features.\\n\\nTherefore, the rephrased question is: \"What features are available in BNI Mobile Banking?\"', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='berdasarkan pertanyaan terakhir, Fitur mana yang menjadi unggulan?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='The question \"berdasarkan pertanyaan terakhir, Fitur mana yang menjadi unggulan?\" can be rephrased as \"What is the standout feature of BNI Mobile Banking?\".\\n\\nThe previous question was about the features available in BNI Mobile Banking. The rephrased question is a standalone question that can be understood without the chat history. \\n\\nTherefore, the rephrased question is: \"What is the standout feature of BNI Mobile Banking?\"', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ff4a55",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dibimbing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
